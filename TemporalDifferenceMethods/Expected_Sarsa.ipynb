{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Sarsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Q_learning, but instead of using the maximum over the next state-action pairs, it takes into account the probability of each action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake8x8-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_probs(Q,state,epsilon):\n",
    "    #returns probability of each action for a given state\n",
    "    probs = np.zeros((Q.shape[1]))+epsilon/Q.shape[1]\n",
    "    best_action = Q[state,:].argmax()\n",
    "    probs[best_action] += 1 - epsilon\n",
    "    return probs\n",
    "\n",
    "def choose_action(pi_probs,n_actions):\n",
    "    #returns action based on policy\n",
    "    return np.random.choice(range(n_actions),p=pi_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_sarsa(env,n_episodes,alpha,gamma,epsilon):\n",
    "    \n",
    "    n_states = env.observation_space.n\n",
    "    n_actions = env.action_space.n\n",
    "    \n",
    "    #initialize action-value function\n",
    "    Q = np.zeros((n_states,n_actions)) + 0.5\n",
    "    Q[n_states-1,:] = np.zeros(n_actions)\n",
    "    \n",
    "    for n in range(n_episodes):\n",
    "        \n",
    "        next_state = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        #generate episode\n",
    "        while not done:\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            #choose action based on policy\n",
    "            action = choose_action(epsilon_greedy_probs(Q,state,epsilon),n_actions)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            #action probabilities for the update\n",
    "            probs = epsilon_greedy_probs(Q,next_state,epsilon)\n",
    "            \n",
    "            #TD update of action-value function\n",
    "            Q[state,action] += alpha * (reward + gamma * np.sum(probs[a]*Q[next_state,a] for a in range(n_actions)) - Q[state,action])\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = expected_sarsa(env,2000,0.8,0.9,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08066885, 0.14535178, 0.11825139, 0.0802569 ],\n",
       "       [0.09663394, 0.08613346, 0.1434457 , 0.08920343],\n",
       "       [0.09472482, 0.10026158, 0.0959848 , 0.09822764],\n",
       "       [0.09892794, 0.09373709, 0.11474356, 0.09608107],\n",
       "       [0.10215154, 0.10320402, 0.09618632, 0.1003031 ],\n",
       "       [0.09917179, 0.10511685, 0.08573673, 0.106244  ],\n",
       "       [0.13455549, 0.08882224, 0.08750541, 0.08906736],\n",
       "       [0.08980127, 0.0891297 , 0.08651857, 0.10817246],\n",
       "       [0.09296721, 0.14445293, 0.09020543, 0.09364567],\n",
       "       [0.10404896, 0.15139764, 0.10323301, 0.13322339],\n",
       "       [0.10603294, 0.10989229, 0.11980438, 0.10274475],\n",
       "       [0.1111543 , 0.11915072, 0.11932586, 0.13216059],\n",
       "       [0.1771494 , 0.11768624, 0.11348556, 0.10374275],\n",
       "       [0.11473333, 0.11435696, 0.11142432, 0.11399737],\n",
       "       [0.12103909, 0.28247331, 0.20988722, 0.12122316],\n",
       "       [0.09484069, 0.21142175, 0.0941869 , 0.0984563 ],\n",
       "       [0.12529295, 0.10827381, 0.21397794, 0.12414673],\n",
       "       [0.15959288, 0.27412251, 0.15994128, 0.14986744],\n",
       "       [0.13695639, 0.1594607 , 0.21545786, 0.1610033 ],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.29232367, 0.15986053, 0.17507245, 0.16285231],\n",
       "       [0.19597709, 0.16179528, 0.15299154, 0.13487002],\n",
       "       [0.35184591, 0.2211512 , 0.1310689 , 0.12844714],\n",
       "       [0.30932636, 0.25667473, 0.11117047, 0.10985894],\n",
       "       [0.12288323, 0.23416228, 0.15912364, 0.15950872],\n",
       "       [0.17761585, 0.30743363, 0.15405172, 0.2048998 ],\n",
       "       [0.28003553, 0.25448072, 0.16705184, 0.34622272],\n",
       "       [0.28987321, 0.27101565, 0.44896135, 0.26589412],\n",
       "       [0.2783054 , 0.28617394, 0.27299525, 0.36042612],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.25490123, 0.32619365, 0.19209158, 0.21211817],\n",
       "       [0.17318658, 0.34404596, 0.24334281, 0.24763049],\n",
       "       [0.21335706, 0.2669092 , 0.24829195, 0.20270478],\n",
       "       [0.29577413, 0.31985945, 0.28550258, 0.20885303],\n",
       "       [0.27756169, 0.23496861, 0.41743353, 0.23573866],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.2987325 , 0.30368985, 0.277176  , 0.42137996],\n",
       "       [0.32009074, 0.38086307, 0.31255467, 0.31182344],\n",
       "       [0.29728647, 0.449849  , 0.27854925, 0.2944113 ],\n",
       "       [0.33822479, 0.42775336, 0.28576603, 0.26274942],\n",
       "       [0.27067741, 0.25620841, 0.26323659, 0.41461309],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.4504    , 0.4504    , 0.37939534, 0.37558442],\n",
       "       [0.38489338, 0.44072214, 0.34686911, 0.3899381 ],\n",
       "       [0.36792479, 0.4499786 , 0.37170961, 0.38889945],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.40138939, 0.43728074, 0.52822309, 0.36436137],\n",
       "       [0.20436226, 0.29584249, 0.21188577, 0.20484477],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.46      , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.46      , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.46      , 0.46      , 0.46      , 0.46      ],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.46      , 0.97933546, 0.44722167, 0.46      ],\n",
       "       [0.1923784 , 0.19643166, 0.20240705, 0.38538708],\n",
       "       [0.34840763, 0.35501088, 0.40924867, 0.34182122],\n",
       "       [0.3876046 , 0.37826034, 0.41364032, 0.44999019],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.46      , 0.45928   , 0.46      , 0.5       ],\n",
       "       [0.46      , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
